{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: 'SOS', 1: 'EOS'}\n",
    "        self.n_words = 2\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip()) # lowercase all characters and strip both ends\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s) # remove special characters except ? and !\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j ai pige ! ! ? '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"             J'ai pig√© ! 1234!@#%^*&(*(?))                  \"\n",
    "normalize_string(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(lang1, lang2, reverse=False):\n",
    "    print('Reading lines...')\n",
    "    \n",
    "    lines = open('./data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # check for reverse\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        original_lang = Lang(lang1)\n",
    "        translated_lang = Lang(lang2)\n",
    "    else:\n",
    "        original_lang = Lang(lang2)\n",
    "        translated_lang = Lang(lang1)\n",
    "        \n",
    "    return original_lang, translated_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 10\n",
    "\n",
    "eng_prefixes = ('i am', 'i m')\n",
    "\n",
    "def filter_pair(p):\n",
    "    return (len(p[0].split(' ')) < MAX_LEN and len(p[1].split(' ')) < MAX_LEN and p[1].startswith(eng_prefixes))\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Total number of pairs: 135842\n",
      "Trimmed to 4534 number of pairs\n",
      "Counting words...\n",
      "eng 2405\n",
      "fra 1792\n",
      "['j ai ans .', 'i m .']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1, lang2, reverse=False):\n",
    "    original, translated, pairs = read_file(lang1, lang2, reverse)\n",
    "    print('Total number of pairs:', len(pairs))\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print('Trimmed to %s number of pairs' % len(pairs))\n",
    "    print('Counting words...')\n",
    "    for pair in pairs:\n",
    "        original.addSentence(pair[0])\n",
    "        translated.addSentence(pair[1])\n",
    "    print(original.name, original.n_words)\n",
    "    print(translated.name, translated.n_words)\n",
    "    \n",
    "    return original, translated, pairs\n",
    "    \n",
    "original, translated, pairs = prepare_data('eng', 'fra', reverse=True)\n",
    "print(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embed = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        embedding = self.embed(x)\n",
    "        output, h = self.gru(embedding, h)\n",
    "        \n",
    "        return output, h\n",
    "    \n",
    "    def init_hidden_weights(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.embed = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out = F.relu(self.embed(x).view(1, 1, -1))\n",
    "        out, h = self.gru(out, h)\n",
    "        out = self.softmax(self.fc(out[0]))\n",
    "    \n",
    "    def init_hidden_weights(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing training data\n",
    "EOS_TOKEN=1\n",
    "SOS_TOKEN=0\n",
    "\n",
    "def index_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensor_from_sentence(lang, sentence):\n",
    "    idx = index_from_sentence(lang, sentence)\n",
    "    idx.append(EOS_TOKEN)\n",
    "    \n",
    "    return torch.tensor(idx, type=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensor_from_pair(pair):\n",
    "    feature = tensor_from_sentence(lang, pair[0])\n",
    "    target = tensor_from_sentence(lang, pair[1])\n",
    "    \n",
    "    return (feature, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_teacher_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LEN):\n",
    "    encoder_hidden = encoder.init_hidden_weights()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    output_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_output[0,0]\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < force_teacher_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        for i in range(target_length):\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
